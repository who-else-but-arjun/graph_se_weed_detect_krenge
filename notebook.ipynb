{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-02-02T20:20:18.116711Z",
     "iopub.status.busy": "2025-02-02T20:20:18.116421Z",
     "iopub.status.idle": "2025-02-02T20:20:21.699503Z",
     "shell.execute_reply": "2025-02-02T20:20:21.698476Z",
     "shell.execute_reply.started": "2025-02-02T20:20:18.116690Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-02-02T20:20:21.700911Z",
     "iopub.status.busy": "2025-02-02T20:20:21.700688Z",
     "iopub.status.idle": "2025-02-02T20:20:25.184971Z",
     "shell.execute_reply": "2025-02-02T20:20:25.184070Z",
     "shell.execute_reply.started": "2025-02-02T20:20:21.700891Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install numpy scipy scikit-learn matplotlib pandas tqdm opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-02-02T20:20:25.187303Z",
     "iopub.status.busy": "2025-02-02T20:20:25.186962Z",
     "iopub.status.idle": "2025-02-02T20:20:28.614066Z",
     "shell.execute_reply": "2025-02-02T20:20:28.613187Z",
     "shell.execute_reply.started": "2025-02-02T20:20:25.187278Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-02-02T20:20:28.615788Z",
     "iopub.status.busy": "2025-02-02T20:20:28.615558Z",
     "iopub.status.idle": "2025-02-02T20:20:32.059495Z",
     "shell.execute_reply": "2025-02-02T20:20:32.058392Z",
     "shell.execute_reply.started": "2025-02-02T20:20:28.615768Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:20:32.061098Z",
     "iopub.status.busy": "2025-02-02T20:20:32.060724Z",
     "iopub.status.idle": "2025-02-02T20:20:32.066241Z",
     "shell.execute_reply": "2025-02-02T20:20:32.065361Z",
     "shell.execute_reply.started": "2025-02-02T20:20:32.061061Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from ultralytics import YOLO\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torchvision import transforms\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from torch_geometric.utils import add_self_loops, remove_self_loops\n",
    "from PIL import Image\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:20:32.067263Z",
     "iopub.status.busy": "2025-02-02T20:20:32.067021Z",
     "iopub.status.idle": "2025-02-02T20:40:39.480847Z",
     "shell.execute_reply": "2025-02-02T20:40:39.479843Z",
     "shell.execute_reply.started": "2025-02-02T20:20:32.067243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11s.pt\")\n",
    "\n",
    "model.train(\n",
    "    data=\"yaml-files/dataset.yaml\",\n",
    "    epochs=500,\n",
    "    imgsz=512,\n",
    "    batch=16,\n",
    "    lr0=0.0002,\n",
    "    lrf=0.002,\n",
    "    momentum=0.98,\n",
    "    weight_decay=0.0001,\n",
    "    optimizer=\"RAdam\",\n",
    "    cos_lr = True,\n",
    "    warmup_epochs=30,\n",
    "    iou=0.5,\n",
    "    mosaic=0.0, \n",
    "    dfl = 2.0,\n",
    "    device=\"cuda\",\n",
    "    augment=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:58:32.304695Z",
     "iopub.status.busy": "2025-02-02T20:58:32.304364Z",
     "iopub.status.idle": "2025-02-02T20:58:44.565380Z",
     "shell.execute_reply": "2025-02-02T20:58:44.564626Z",
     "shell.execute_reply.started": "2025-02-02T20:58:32.304664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_features(image_paths,device=\"cuda\"):\n",
    "    features = []\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        img = transform(Image.open(img_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            feat1 = model.model.model[0:5](img)\n",
    "            feat2 = model.model.model[0:10](img)\n",
    "            \n",
    "            feat1_pooled = torch.cat([\n",
    "                torch.mean(feat1, dim=[2, 3]),\n",
    "                torch.max(feat1, dim=3)[0].max(dim=2)[0]\n",
    "            ], dim=1)\n",
    "            \n",
    "            feat2_pooled = torch.cat([\n",
    "                torch.mean(feat2, dim=[2, 3]),\n",
    "                torch.max(feat2, dim=3)[0].max(dim=2)[0]\n",
    "            ], dim=1)\n",
    "            \n",
    "            combined_feat = torch.cat([feat1_pooled, feat2_pooled], dim=1)\n",
    "            features.append(combined_feat.view(-1).cpu().numpy())\n",
    "    \n",
    "    features = np.array(features)\n",
    "    features = (features - features.mean(axis=0)) / (features.std(axis=0) + 1e-6)\n",
    "    return features\n",
    "\n",
    "labeled_image_paths = [\"dataset/labeled/images/\" + f for f in os.listdir(\"dataset/labeled/images\")]\n",
    "unlabeled_image_paths = [\"dataset/unlabeled/\" + f for f in os.listdir(\"dataset/unlabeled\")]\n",
    "\n",
    "labeled_features = extract_features(labeled_image_paths)\n",
    "unlabeled_features = extract_features(unlabeled_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:58:49.773620Z",
     "iopub.status.busy": "2025-02-02T20:58:49.773327Z",
     "iopub.status.idle": "2025-02-02T20:58:49.920876Z",
     "shell.execute_reply": "2025-02-02T20:58:49.920132Z",
     "shell.execute_reply.started": "2025-02-02T20:58:49.773598Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def construct_knn_graph(features, k=15):\n",
    "    distances = pairwise_distances(features)\n",
    "    sigma = np.mean(np.sort(distances, axis=1)[:, 1:k+1])\n",
    "    weights = np.exp(-distances**2 / (2 * sigma**2))\n",
    "    \n",
    "    adjacency_matrix = kneighbors_graph(features, k, mode=\"connectivity\", include_self=False)\n",
    "    edge_index_np = np.array(adjacency_matrix.nonzero())\n",
    "    edge_weights_np = weights[adjacency_matrix.nonzero()]\n",
    "    edge_index = torch.tensor(edge_index_np, dtype=torch.long)\n",
    "    edge_weights = torch.tensor(edge_weights_np, dtype=torch.float32)\n",
    "    \n",
    "    edge_index, edge_weights = add_self_loops(edge_index, edge_weights, num_nodes=len(features))\n",
    "    return edge_index, edge_weights\n",
    "\n",
    "edge_index, edge_weights = construct_knn_graph(np.vstack([labeled_features, unlabeled_features]))\n",
    "num_nodes = len(labeled_features) + len(unlabeled_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:58:52.733897Z",
     "iopub.status.busy": "2025-02-02T20:58:52.733601Z",
     "iopub.status.idle": "2025-02-02T20:58:52.909894Z",
     "shell.execute_reply": "2025-02-02T20:58:52.908973Z",
     "shell.execute_reply.started": "2025-02-02T20:58:52.733874Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_labels(label_paths):\n",
    "    labels = []\n",
    "    for label_path in label_paths:\n",
    "        with open(label_path, \"r\") as f:\n",
    "            class_ids = [int(line.split()[0]) for line in f.readlines()]\n",
    "        labels.append(max(set(class_ids)) if class_ids else 0)\n",
    "    return np.array(labels)\n",
    "\n",
    "labeled_label_paths = [f\"dataset/labeled/labels/{os.path.basename(p).rsplit('.', 1)[0]}.txt\" for p in labeled_image_paths]\n",
    "actual_labels = load_labels(labeled_label_paths)\n",
    "graph_data = Data(\n",
    "    x=torch.tensor(np.vstack([labeled_features, unlabeled_features]), dtype=torch.float32),\n",
    "    edge_index=edge_index,\n",
    "    y=torch.cat([torch.tensor(actual_labels, dtype=torch.long), \n",
    "                torch.full((len(unlabeled_features),), -1)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:58:55.825626Z",
     "iopub.status.busy": "2025-02-02T20:58:55.825309Z",
     "iopub.status.idle": "2025-02-02T20:58:55.831467Z",
     "shell.execute_reply": "2025-02-02T20:58:55.830468Z",
     "shell.execute_reply.started": "2025-02-02T20:58:55.825602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "unique_labels, counts = np.unique(graph_data.y.numpy(), return_counts=True)\n",
    "print(\"✅ Fixed Graph Data Labels:\", dict(zip(unique_labels, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:58:58.765010Z",
     "iopub.status.busy": "2025-02-02T20:58:58.764718Z",
     "iopub.status.idle": "2025-02-02T20:58:58.812329Z",
     "shell.execute_reply": "2025-02-02T20:58:58.811444Z",
     "shell.execute_reply.started": "2025-02-02T20:58:58.764989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=128, num_classes=2):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GATConv(in_dim, hidden_dim, heads=8, dropout=0.5)\n",
    "        self.conv2 = GATConv(hidden_dim * 8, hidden_dim, heads=8, dropout=0.5)\n",
    "        self.conv3 = GCNConv(hidden_dim * 8, hidden_dim)\n",
    "        self.lin = nn.Linear(hidden_dim, num_classes)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(hidden_dim * 8)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_dim * 8)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.elu(x)\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.elu(x)\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.elu(x)\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "gnn_model = GNN(in_dim=graph_data.x.shape[1])\n",
    "optimizer = torch.optim.AdamW(gnn_model.parameters(), lr=0.0005, weight_decay=0.01, amsgrad=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:59:05.358308Z",
     "iopub.status.busy": "2025-02-02T20:59:05.357878Z",
     "iopub.status.idle": "2025-02-02T20:59:05.364368Z",
     "shell.execute_reply": "2025-02-02T20:59:05.363327Z",
     "shell.execute_reply.started": "2025-02-02T20:59:05.358271Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_loss(out, graph_data, pseudo_labels, pseudo_mask):\n",
    "    labeled_mask = graph_data.y != -1\n",
    "    supervised_loss = F.nll_loss(out[labeled_mask], graph_data.y[labeled_mask])\n",
    "    \n",
    "    pseudo_loss = 0.0\n",
    "    if pseudo_mask.any():\n",
    "        pseudo_loss = F.nll_loss(out[pseudo_mask], pseudo_labels[pseudo_mask])\n",
    "    \n",
    "    edge_index, _ = remove_self_loops(graph_data.edge_index)\n",
    "    smoothness_loss = torch.mean(torch.pow(\n",
    "        out[edge_index[0]] - out[edge_index[1]], 2\n",
    "    ))\n",
    "    \n",
    "    pseudo_weight = min(0.3, gnn_model.training_step / 100)\n",
    "    total_loss = supervised_loss + pseudo_weight * pseudo_loss + 0.1 * smoothness_loss\n",
    "    \n",
    "    return total_loss, {\n",
    "        'supervised': supervised_loss.item(),\n",
    "        'pseudo': pseudo_loss.item() if isinstance(pseudo_loss, torch.Tensor) else pseudo_loss,\n",
    "        'smoothness': smoothness_loss.item(),\n",
    "        'total': total_loss.item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T20:59:10.376812Z",
     "iopub.status.busy": "2025-02-02T20:59:10.376496Z",
     "iopub.status.idle": "2025-02-02T20:59:10.383016Z",
     "shell.execute_reply": "2025-02-02T20:59:10.381614Z",
     "shell.execute_reply.started": "2025-02-02T20:59:10.376788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_pseudo_labels(model, graph_data, confidence_threshold=0.9):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(graph_data.x, graph_data.edge_index)\n",
    "        probs = torch.exp(out)\n",
    "        max_probs, pseudo_labels = probs.max(dim=1)\n",
    "        \n",
    "        unlabeled_mask = graph_data.y == -1\n",
    "        mean_confidence = max_probs[unlabeled_mask].mean()\n",
    "        adaptive_threshold = min(confidence_threshold, mean_confidence + 0.1)\n",
    "        \n",
    "        confidence_mask = (max_probs > adaptive_threshold) & unlabeled_mask\n",
    "        \n",
    "        if confidence_mask.any():\n",
    "            class_dist = torch.bincount(pseudo_labels[confidence_mask])\n",
    "            if len(class_dist) > 1:\n",
    "                ratio = float(class_dist.max()) / class_dist.min()\n",
    "                if ratio > 3:\n",
    "                    minor_class = class_dist.argmin()\n",
    "                    confidence_mask &= ((pseudo_labels == minor_class) | \n",
    "                                     (max_probs > (adaptive_threshold + 0.1)))\n",
    "        \n",
    "        return pseudo_labels, confidence_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-02-02T20:59:38.355015Z",
     "iopub.status.busy": "2025-02-02T20:59:38.354715Z",
     "iopub.status.idle": "2025-02-02T21:02:58.517938Z",
     "shell.execute_reply": "2025-02-02T21:02:58.517149Z",
     "shell.execute_reply.started": "2025-02-02T20:59:38.354994Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gnn_model.training_step = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(250):\n",
    "    gnn_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = gnn_model(graph_data.x, graph_data.edge_index)\n",
    "    \n",
    "    pseudo_labels, confidence_mask = generate_pseudo_labels(gnn_model, graph_data)\n",
    "    loss, loss_components = calculate_loss(out, graph_data, pseudo_labels, confidence_mask)\n",
    "    \n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(gnn_model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step(loss_components['total'])\n",
    "    \n",
    "    gnn_model.training_step += 1\n",
    "    \n",
    "    if loss_components['total'] < best_loss:\n",
    "        best_loss = loss_components['total']\n",
    "        torch.save(gnn_model.state_dict(), 'WEED.pt')\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"\\nEpoch {epoch}:\")\n",
    "        for k, v in loss_components.items():\n",
    "            print(f\"{k.capitalize()} Loss: {v:.4f}\")\n",
    "        print(f\"Confident Pseudo Labels: {confidence_mask.sum().item()}\")\n",
    "        if confidence_mask.any():\n",
    "            print(f\"Class distribution: {torch.bincount(pseudo_labels[confidence_mask])}\")\n",
    "\n",
    "gnn_model.load_state_dict(torch.load('WEED.pt'))\n",
    "gnn_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    final_out = gnn_model(graph_data.x, graph_data.edge_index)\n",
    "    pseudo_labels = final_out.argmax(dim=1)\n",
    "    confidence_mask = torch.exp(final_out).max(dim=1)[0] > 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T21:03:17.958922Z",
     "iopub.status.busy": "2025-02-02T21:03:17.958607Z",
     "iopub.status.idle": "2025-02-02T21:03:17.965161Z",
     "shell.execute_reply": "2025-02-02T21:03:17.964270Z",
     "shell.execute_reply.started": "2025-02-02T21:03:17.958899Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "unique_preds, counts_preds = np.unique(pseudo_labels, return_counts=True)\n",
    "print(\"✅ Predicted class distribution:\", dict(zip(unique_preds, counts_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T21:03:22.439454Z",
     "iopub.status.busy": "2025-02-02T21:03:22.439135Z",
     "iopub.status.idle": "2025-02-02T21:03:22.444792Z",
     "shell.execute_reply": "2025-02-02T21:03:22.444020Z",
     "shell.execute_reply.started": "2025-02-02T21:03:22.439430Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"graph_data.x shape:\", graph_data.x.shape)\n",
    "print(\"Max index in edge_index:\", edge_index.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-02-02T21:03:25.316741Z",
     "iopub.status.busy": "2025-02-02T21:03:25.316423Z",
     "iopub.status.idle": "2025-02-02T21:04:03.227854Z",
     "shell.execute_reply": "2025-02-02T21:04:03.227229Z",
     "shell.execute_reply.started": "2025-02-02T21:03:25.316713Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_pseudo_labels(pseudo_labels, confidence_mask, unlabeled_image_paths, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for idx, (img_path, label, is_confident) in enumerate(zip(\n",
    "            unlabeled_image_paths, \n",
    "            pseudo_labels[len(labeled_image_paths):], \n",
    "            confidence_mask[len(labeled_image_paths):])):\n",
    "        \n",
    "        if is_confident:\n",
    "            img_name = os.path.basename(img_path).rsplit('.', 1)[0]\n",
    "            label_path = os.path.join(output_dir, f\"{img_name}.txt\")\n",
    "            results = model(img_path)\n",
    "            \n",
    "            with open(label_path, \"w\") as f:\n",
    "                for result in results:\n",
    "                    for box in result.boxes:\n",
    "                        if box.conf > 0.6:\n",
    "                            x_center, y_center, width, height = box.xywhn.cpu().numpy().flatten()\n",
    "                            f.write(f\"{int(label.item())} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "save_pseudo_labels(\n",
    "    pseudo_labels,\n",
    "    confidence_mask,\n",
    "    unlabeled_image_paths,\n",
    "    \"dataset/unlabeled/labels/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T21:06:51.471148Z",
     "iopub.status.busy": "2025-02-02T21:06:51.470798Z",
     "iopub.status.idle": "2025-02-02T21:06:53.648354Z",
     "shell.execute_reply": "2025-02-02T21:06:53.647467Z",
     "shell.execute_reply.started": "2025-02-02T21:06:51.471121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"dataset_updated/images\", exist_ok=True)\n",
    "os.makedirs(\"dataset_updated/labels\", exist_ok=True)\n",
    "for file in os.listdir(\"dataset/labeled/images/\"):\n",
    "    src = os.path.join(\"dataset/labeled/images\", file)\n",
    "    dst = os.path.join(\"dataset_updated/images\", file)\n",
    "    if os.path.isfile(src):\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "for file in os.listdir(\"dataset/unlabeled/\"):\n",
    "    src = os.path.join(\"dataset/unlabeled\", file)\n",
    "    dst = os.path.join(\"dataset_updated/images\", file)\n",
    "    if os.path.isfile(src):\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "shutil.copytree(\"unlabeled/labels/\", \"dataset_updated/labels/\", dirs_exist_ok=True)\n",
    "shutil.copytree(\"dataset/labeled/labels/\", \"dataset_updated/labels/\", dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T21:08:00.552147Z",
     "iopub.status.busy": "2025-02-02T21:08:00.551796Z",
     "iopub.status.idle": "2025-02-02T22:29:06.448736Z",
     "shell.execute_reply": "2025-02-02T22:29:06.447750Z",
     "shell.execute_reply.started": "2025-02-02T21:08:00.552114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.train(\n",
    "    data=\"yaml-files/dataset_updated.yaml\",\n",
    "    epochs=500,\n",
    "    imgsz=512,\n",
    "    batch=64,\n",
    "    lr0=0.0002,\n",
    "    lrf=0.0025,\n",
    "    momentum=0.98,\n",
    "    weight_decay=0.0001,\n",
    "    optimizer=\"RAdam\",\n",
    "    cos_lr = True,\n",
    "    warmup_epochs=30,\n",
    "    iou=0.5,\n",
    "    mosaic=0.0,\n",
    "    dfl = 1.5,\n",
    "    augment=True,\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T22:53:57.467915Z",
     "iopub.status.busy": "2025-02-02T22:53:57.467486Z",
     "iopub.status.idle": "2025-02-02T22:54:02.397270Z",
     "shell.execute_reply": "2025-02-02T22:54:02.396212Z",
     "shell.execute_reply.started": "2025-02-02T22:53:57.467880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = YOLO(\"train_final/best.pt\")\n",
    "metrics = model.val(data=\"yaml-files/test.yaml\", device=\"cuda\")\n",
    "precision = metrics.box.p.mean()  # ✅ Mean Precision\n",
    "recall = metrics.box.r.mean()  # ✅ Mean Recall\n",
    "map_50 = metrics.box.map50  # ✅ mAP@50\n",
    "map_50_95 = metrics.box.map  # ✅ mAP@50-95\n",
    "\n",
    "f1_score = (2 * precision * recall) / (precision + recall + 1e-6) \n",
    "print(f\"✅ Mean Precision : {precision:.4f}\")\n",
    "print(f\"✅ Mean Recall : {recall:.4f}\")\n",
    "print(f\"✅ mAP@50 : {map_50:.4f}\")\n",
    "print(f\"✅ mAP@50-95 : {map_50_95:.4f}\")\n",
    "print(f\"✅ Mean F1-Score : {f1_score:.4f}\")\n",
    "\n",
    "final_score = 0.5*f1_score + 0.5*map_50_95\n",
    "print(f\"✅ Final Score : {final_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6591200,
     "sourceId": 10644848,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6591211,
     "sourceId": 10644867,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
